{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "04. 소프트맥스 회귀 연습",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOBfecc+yi82z039k1Hftxt",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "693f6203656845cf9fa3168f7d1dce3d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_f1a06a79be5d4061b1dfc310bc7bdd82",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_3f23203da5ba4c2fb972583f3e8081ee",
              "IPY_MODEL_cbe3cf628c8b422b85dee2f829073bd3"
            ]
          }
        },
        "f1a06a79be5d4061b1dfc310bc7bdd82": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "3f23203da5ba4c2fb972583f3e8081ee": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_df758e1bbefb4a9a8a4c9ac82f06e818",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "info",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_99fef8f4ef474af197314e6a3a13ff71"
          }
        },
        "cbe3cf628c8b422b85dee2f829073bd3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_510c7ce760f4421db97c9640fb939fe2",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 9920512/? [00:19&lt;00:00, 802989.25it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_e0efc2c9d159482fbf16cc0e67ab29e0"
          }
        },
        "df758e1bbefb4a9a8a4c9ac82f06e818": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "99fef8f4ef474af197314e6a3a13ff71": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "510c7ce760f4421db97c9640fb939fe2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "e0efc2c9d159482fbf16cc0e67ab29e0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "493ce21d0798448a8753eee4562e16fd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_4acec282f9894f67af0101ceee42015e",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_311faeed821a4195bdda4d9c0b8edbc7",
              "IPY_MODEL_326e3389a3ae44d1a28ebb1e712877f8"
            ]
          }
        },
        "4acec282f9894f67af0101ceee42015e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "311faeed821a4195bdda4d9c0b8edbc7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_b10a2af961ab4896892ce9de593790de",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_cf144e214ee448848bd0c02582100097"
          }
        },
        "326e3389a3ae44d1a28ebb1e712877f8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_d2a8fcf15b434f3baa46b419cf47ea97",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 32768/? [00:00&lt;00:00, 110736.68it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_56464e935572456da5fd1e6d8a72dc6c"
          }
        },
        "b10a2af961ab4896892ce9de593790de": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "cf144e214ee448848bd0c02582100097": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "d2a8fcf15b434f3baa46b419cf47ea97": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "56464e935572456da5fd1e6d8a72dc6c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "714e23d021bb4dbf8b629506df88de51": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_2ebacef163bb4be6991156425c59683e",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_212dcc6212d6430d9ba5cdeb81ab9e3f",
              "IPY_MODEL_28d7bcc4aafa45ff826065d24d1cb159"
            ]
          }
        },
        "2ebacef163bb4be6991156425c59683e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "212dcc6212d6430d9ba5cdeb81ab9e3f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_bd0575fca92a401a96295924f85ded2f",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "info",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_11c71dc1784542ff8e2245346931a468"
          }
        },
        "28d7bcc4aafa45ff826065d24d1cb159": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_5962701d113f471f8b031106fd02d2e4",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 1654784/? [00:18&lt;00:00, 492246.68it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_5f799bf348014204ba9c46953a314ea9"
          }
        },
        "bd0575fca92a401a96295924f85ded2f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "11c71dc1784542ff8e2245346931a468": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "5962701d113f471f8b031106fd02d2e4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "5f799bf348014204ba9c46953a314ea9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "8a9a1e37adca49529b8d50f999fe3fda": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_01872a52096242c6bfc188b392da086e",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_ed0463892ba0496cb139a9285860cf8a",
              "IPY_MODEL_bff971b14fd7491a85424e1a7b6260ba"
            ]
          }
        },
        "01872a52096242c6bfc188b392da086e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ed0463892ba0496cb139a9285860cf8a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_da3f26497d9643d2999ce94f5aa0122c",
            "_dom_classes": [],
            "description": "  0%",
            "_model_name": "FloatProgressModel",
            "bar_style": "info",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 0,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_4e4296cb8eb648ff9e628228faa992f3"
          }
        },
        "bff971b14fd7491a85424e1a7b6260ba": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_5cd808865e024663b532507e26b0135f",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 0/4542 [00:00&lt;?, ?it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_e47cd5d9bbb943a8927b129c79e424b3"
          }
        },
        "da3f26497d9643d2999ce94f5aa0122c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "4e4296cb8eb648ff9e628228faa992f3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "5cd808865e024663b532507e26b0135f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "e47cd5d9bbb943a8927b129c79e424b3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Hyunsooooo/Pytorch-/blob/main/04_%EC%86%8C%ED%94%84%ED%8A%B8%EB%A7%A5%EC%8A%A4_%ED%9A%8C%EA%B7%80_%EC%97%B0%EC%8A%B5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0WsDOYC95Dx7"
      },
      "source": [
        "# 소프트맥스 회귀(Softmax Regression)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2NzmH0Wl8bRq"
      },
      "source": [
        "## 4.1 원-핫 인코딩\r\n",
        "\r\n",
        "이번 챕터에서는 범주형 데이터를 처리할 때 레이블을 표현하는 방법인 원-핫 인코딩에 대해서 배워봅시다"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lU2iXhFD6FJ3"
      },
      "source": [
        "### 4.1.1 원-핫 인코딩(One-Hot Encoding)\r\n",
        "\r\n",
        "원-핫 인코딩은 서택해야 하는 선택지의 개수만큼의 차원을 가지면서, 각 선택지의 인덱스에 해당하는 원소에는 1, 나머지 원소에는 0의 값을 가지도록 하는 표현 방법.\r\n",
        "예를 들어, 강아지 고양이 냉장고 3개의 선택지가 있다고 가정\r\n",
        "\r\n",
        "원-핫 인코딩을 하기 위해서는 선택지에 순차적으로 정수 인덱스를 부여한다. 임의로 강아지는 0번 , 고양이 1번, 냉장고 2 번 부여했다고 하면 각 선택지에 대해 원-핫 인코딩이 된 벡터는 다음과 같다.\r\n",
        "\r\n",
        "강아지 = [1,0,0]\r\n",
        "\r\n",
        "고양이 = [0,1,0]\r\n",
        "\r\n",
        "냉장공 = [0,0,1]\r\n",
        "\r\n",
        "총 선택지는 3개였으므로 위 벡터들은 전부 3차원의 벡터가 되었다. 그리고 각 선택지의 벡터들을 보면 해당 선택지의 인덱스에만 1의 값을 가지고, 나머지 원소들은 0의 값을 가진다. 예를들어 고양이는 1번 인덱스였으므로, 원-핫 인코딩에서 얻은 벡터에서 1번 인덱스에만 1의 값을 가지는 것을 볼 수 있다.\r\n",
        "\r\n",
        "이와 같이 원-핫 인코딩으로 표현된 벡터를 원-핫 벡터 라고 한다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ixL7s03G7Ptf"
      },
      "source": [
        "### 4.1.2. 원-핫 벡터의 무작위성\r\n",
        "\r\n",
        "꼭 실제값을 원-핫 벡터로 표현해야만 다중 클래스 분류 문제를 풀 수 있는 것은 아니지만, 대부분의 다중 클래스 분류 문제가 각 클래스 간의 관계가 균등하다는 점에서 원-핫 벡터는 이러한 점을 표현할 수 있는 적절한 방법이다.\r\n",
        "\r\n",
        "다수의 클래스를 분류하는 문제에서는 이진 분류처럼 2개의 숫자 레이블이 아니라 클래스의 개수만큼 숫자 레이블이 필요하다. 이때 직관적으로 생각해볼 수 있는 레이블링 방법은 분류해야 할 클래스 전체에 정수 인코딩을 하는 것이다. 예를 들어 분류해야할 레이블이 {red,green,glue}와 같이 3개라면 각각 0,1,2 로 레이블을 한다. 또는 분류해야 할 클래스가 4개이고 인덱스를 숫자 0부터 시작하고 싶다면 {baby,child,adolescent,adult} 라면 1,2,3,4로 레이블을 해볼 수 있다. 그런데 일반적인 다중 클래스 분류 문제에서 레이블링 방법으로는 위와 같은 정수 인코딩이 아니라 원-핫 인코딩을 사용하는 것이 보다 클래스의 성질을 잘 표현했다고 할 수 있다.\r\n",
        "\r\n",
        "Banana , Tomato, Apple 이라는 3개의 클래스가 존재하는 문제가 있다고 해보자. 레이블은 정수 인코딩을 사용하여 각각 1,2,3 을 부여하였다. 손실 함수로 선형 회귀 챕터에서 배운 평균 제곱 오차 MSE를 사용하면 정수 인코딩이 어떤 오해를 불러일으킬 수 있는지 확인할 수 있다.\r\n",
        "아래의 식은 MSE인데 y헷은 예측값을 의미한다.\r\n",
        "\r\n",
        "$Loss\\ function = \\frac{1}{n} \\sum_i^{n} \\left(y_{i} - \\hat{y_{i}}\\right)^2$\r\n",
        "\r\n",
        "직관적인 오차 크기 비교를 위해 제곱 오차로만 판단해보면\r\n",
        "\r\n",
        "$(2-1)^{2} = 1$\r\n",
        "\r\n",
        "실제값이 Apple일때 예측값이 Banana이었다면 제곱 오차는 다음과 같습니다.\r\n",
        "\r\n",
        "$(3-1)^{2} = 4$\r\n",
        "\r\n",
        "즉, Banana과 Tomato 사이의 오차보다 Banana과 Apple의 오차가 더 큽니다. 이는 기계에게 Banana가 Apple보다는 Tomato에 더 가깝다는 정보를 주는 것과 다름없습니다. 더 많은 클래스에 대해서 정수 인코딩을 수행했다고 해봅시다.\r\n",
        "\r\n",
        "{Banana :1, Tomato :2, Apple :3, Strawberry :4, ... Watermelon :10}\r\n",
        "\r\n",
        "이 정수 인코딩은 Banana가 Watermelon보다는 Tomato에 더 가깝다는 의미를 담고 있습니다. 이는 사용자가 부여하고자 했던 정보가 아닙니다. 이러한 정수 인코딩의 순서 정보가 도움이 되는 분류 문제도 물론 있습니다. 바로 각 클래스가 순서의 의미를 갖고 있어서 회귀를 통해서 분류 문제를 풀 수 있는 경우입니다. 예를 들어 {baby, child, adolescent, adult}나 {1층, 2층, 3층, 4층}이나 {10대, 20대, 30대, 40대}와 같은 경우가 이에 해당됩니다. 하지만 일반적인 분류 문제에서는 각 클래스는 순서의 의미를 갖고 있지 않으므로 각 클래스 간의 오차는 균등한 것이 옳습니다. 정수 인코딩과 달리 원-핫 인코딩은 분류 문제 모든 클래스 간의 관계를 균등하게 분배합니다.\r\n",
        "\r\n",
        "아래는 세 개의 카테고리에 대해서 원-핫 인코딩을 통해서 레이블을 인코딩했을 때 각 클래스 간의 제곱 오차가 균등함을 보여준다.\r\n",
        "\r\n",
        "$((1,0,0)-(0,1,0))^{2} = (1-0)^{2} + (0-1)^{2} + (0-0)^{2} = 2$\r\n",
        "\r\n",
        "$((1,0,0)-(0,0,1))^{2} = (1-0)^{2} + (0-0)^{2} + (0-1)^{2} = 2$\r\n",
        "\r\n",
        "다르게 표현하면 모든 클래스에 대해서 원-핫 인코딩을 통해 얻은 원-핫 벡터들은 모든 쌍에 대해서 유클리드 거리를 구해도 전부 유클리드 거리가 동일하다.\r\n",
        "원-핫 벡터는 일처럼 각 클래스의 표현 방법이 무작위성을 가진다는 점을 표현할 수 있다.\r\n",
        "이러한 원-핫 벡터의 관계의 무작위성은 때로는 단어의 유사성을 구할 수 없다는 단점으로도 언급되기도 한다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D0hGErsXAo1y"
      },
      "source": [
        "## 4.2 소프트맥스 회귀 (softmax regression) 이해하기\r\n",
        "\r\n",
        "앞서 로지스틱 회귀를 통해 2개의 선택지 중에서 1개를 고르는 이진 분류(binary classification)을 풀어봤습니다. 이번 챕터에서는 소프트맥스 회귀를 통해 3개 이상의 선택지 중에서 1개를 고르는 다중 클래스 분류 (Multi-class classification)을 실습해봅시다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cMMLFxj-BApy"
      },
      "source": [
        "### 4.2.1 다중 클래스 분류\r\n",
        "\r\n",
        "이진 분류가 두 개의 답중 하나를 고르는 문제였다면, 세 개 이상의 답 중 하나를 고르는 문제를 다중 클래스 분류 라고 한다. 아래의 문제는 꽃받침 길이, 꽃받침 넓이, 꽃잎 길이, 꽃잎 넓이 라는 4개의 특성(feature)로 부터 setosa, versicolor, virginica 라는 3개의 붓꽃 품종 중 어떤 품종인지를 예측하는 문제로 전형적인 다중 클래스 분류 문제다.\r\n",
        "\r\n",
        "|SepalLengthCm$(x_1)$|SepalWidthCm$(x_2)$|PetalLengthCm$(x_3)$|PetalWidthCm$(x_4)$|Species$(y)$|\r\n",
        "|---|---|---|---|---|\r\n",
        "|5.1|3.5|1.4|0.2|setosa|\r\n",
        "|4.9|3.0|1.4|0.2|setosa|\r\n",
        "|5.8|2.6|4.0|1.2|versicolor|\r\n",
        "|6.7|3.0|5.2|2.3|virginica|\r\n",
        "|5.6|2.8|4.9|2.0|virginica|\r\n",
        "\r\n",
        "위 붓꽃 품종 분류하기 문제를 어떻게 풀지 고민하기 위해 앞서 배운 로지스틱 회귀의 이진 분류를 복습\r\n",
        "\r\n",
        "이번 챕터 설명에서 입력은 x 가중치는 W, 편향은 B, 출력은  $\\hat{Y} 로 각 변수는 벡터 또는 행렬로 가정한다.\r\n",
        "\r\n",
        "*   $\\hat{Y}$은 예측값이라는 의미를 가지고 있으므로 가설식에서 $H(X)$ 대신 사용되기도 합니다.\r\n",
        "\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NDVcuV2LBd6Q"
      },
      "source": [
        "1) 로지스틱 회귀\r\n",
        "\r\n",
        "로지스틱 회귀에서 시그모이드 함수는 예측값을 0과 1 사이의 값으로 만든다. 예를 들어 스팸 메일 분류기를 ㄹ지스틱 회귀로 구현하였을 때, 출력이 0.75 라면 이는 이메일이 스팸일 확률이 75프로 라는 의미가 된다. 반대로 스팸 메일이 아닐 확률은 0.25가 된다. 이 두 확률의 총 합은 1이다\r\n",
        "\r\n",
        "![대체 텍스트](https://wikidocs.net/images/page/59427/%EB%A1%9C%EC%A7%80%EC%8A%A4%ED%8B%B1%ED%9A%8C%EA%B7%80.PNG)\r\n",
        "\r\n",
        "가설 : $H(X) = sigmoid(WX + B)$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jI3sRBFp2rOC"
      },
      "source": [
        "2) 소프트맥스 회귀\r\n",
        "\r\n",
        "소프트맥스 회귀는 확률의 총합이 1이 되는 아이디어를 다중 클래스 분류 문제에 적용한다. 소프트맥스 회귀는 각 클래스. 즉, 각 선택지마다 소수 확률을 할당한다. 이 때 총 확률의 합은 1이 되어야 한다. 이렇게 되면 각 선택지가 정답일 확률로 표현된다.\r\n",
        "\r\n",
        "![대체 텍스트](https://wikidocs.net/images/page/59427/%EC%86%8C%ED%94%84%ED%8A%B8%EB%A7%A5%EC%8A%A4%ED%9A%8C%EA%B7%80.PNG)\r\n",
        "\r\n",
        "결국 소프트맥스 회귀는 선택지의 개수만큼의 차원을 가지는 벡터를 만들고, 해당 벡터가 벡터의 모든 원소의 합이 1이 되도록 원소들의 값을 변환시키는 어떤 함수를 지나게 만들어야 한다. 위의 그림은 붓꽃 품종 분류하기 문제 등과 같이 선택지의 개수가 3개일때, 3차원 벡터가 어떤 함수 ? 를 지나 원소의 총 합이 1이 되도록 원소들의 값이 변환되는 모습을 보여준다. 뒤에서 배우지만이 함수를 softmax 함수라고 부른다.\r\n",
        "\r\n",
        "\r\n",
        "가설 : $H(X) = softmax(WX + B)$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QMMTquWc3LoX"
      },
      "source": [
        "### 4.2.2 소프트맥스 함수\r\n",
        "\r\n",
        "소프트맥스 함수는 분류해야하는 정답지(클래스)의 총 개수를 k 라고 할 때, k차원의 벡터를 입력받아 각 클래스에 대한 확률을 추정한다. 우선 수식에 대해 설명하고, 그 후에는 그림으로 이해해본다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5nkcDTdy3UTQ"
      },
      "source": [
        "1) 소프트맥스 함수의 이해\r\n",
        "\r\n",
        "k차원의 벡터에서 i번째 원소를 zi, i번째 클래스가 정답일 확률을 pi 라고 나타낸다고 했을 때, 소프트맥스 함수는 pi를 다음과 같이 정의한다.\r\n",
        "\r\n",
        "$p_{i}=\\frac{e^{z_{i}}}{\\sum_{j=1}^{k} e^{z_{j}}}\\ \\ for\\ i=1, 2, ... k$\r\n",
        "\r\n",
        "위에서 풀어야하는 문제에 소프트맥스 함수를 차근차근 적용해보자. 위에서 풀어야하는 문제의 경우 k=3 이므로 3차원 벡터  $z=[z_{1}\\ z_{2}\\ z_{3}]$ 의 입력을 받으면 소프트맥스 함수는 아래와 같은 출력을 return 한다.\r\n",
        "\r\n",
        "$softmax(z)=[\\frac{e^{z_{1}}}{\\sum_{j=1}^{3} e^{z_{j}}}\\ \\frac{e^{z_{2}}}{\\sum_{j=1}^{3} e^{z_{j}}}\\ \\frac{e^{z_{3}}}{\\sum_{j=1}^{3} e^{z_{j}}}] = [p_{1}, p_{2}, p_{3}] = \\hat{y} = \\text{예측값}$\r\n",
        "\r\n",
        "p1,p2,p3 각각은 1번 클래스, 2번 클래스, 3번 클래스가 정답일 확률을 나타내며 각각  0과 1 사이의 값으로 총 합은 1이 된다. 여기서 분류하고자 하는 3개의 클래스는 virginica, setosa, versicolor 이므로 이는 결국 각 확률을 나타내는 값을 의미한다. 여기서는 i 가 1 일 때는 virginica, 2 = setosa, 3= versicolor 일 확률이라고 지정하였다 치자. 이 지정 순서는 문제를 풀고자 하는 사람의 무작위 선택이다. 이에 따라 식을 문제에 맞게 다시 쓰면\r\n",
        "\r\n",
        "$softmax(z)=[\\frac{e^{z_{1}}}{\\sum_{j=1}^{3} e^{z_{j}}}\\ \\frac{e^{z_{2}}}{\\sum_{j=1}^{3} e^{z_{j}}}\\ \\frac{e^{z_{3}}}{\\sum_{j=1}^{3} e^{z_{j}}}] = [p_{1}, p_{2}, p_{3}] = [p_{virginica}, p_{setosa}, p_{versicolor}]$\r\n",
        "\r\n",
        "분류하고자 하는 클래스가 k개 일때, k차원의 벡터를 입력받아서 모든 벡터 원소의 값을 0과 1 사이의 값을 값을 변경하여 다시 k차원의 벡터를 리턴한다는 내용을 식으로 기재하였을 뿐이다.\r\n",
        "\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BcJ-EOGa4Fo3"
      },
      "source": [
        "2) 그림을 통한 이해\r\n",
        "\r\n",
        "![대체 텍스트](https://wikidocs.net/images/page/35476/softmax1_final_final.PNG)\r\n",
        "\r\n",
        "위의 그림에 점차 살을 붙여보자 여기서는 샘플 데이터를 1개씩 입력으로 받아 처리한다고 가정하자. 즉 배치 크기가 1이다.\r\n",
        "\r\n",
        "위의 그림에는 두 가지 질문이 있다. 첫 번째 질문은 소프트맥스 함수의 입력에 대한 질문이다. 하나의 샘플 데이터는 4개의 독립 변수 x를 가지는데 이는 모델이 4차원 벡터를 입력으로 받음을 의미한다. 그런데 소프트맥스의 함수의 입력으로 사용되는 벡터는 벡터의 차원이 분류하고자 하는 클래스의 개수가 되어야 하므로, 어떤 가중치 연산을 통해 3차원 벡터로 변환되어야 한다. 위의 그림에서는 함수의 입력으로 사용되는 3차원 벡터를 z로 표현했다.\r\n",
        "\r\n",
        "\r\n",
        "![대체 텍스트](https://wikidocs.net/images/page/35476/softmaxbetween1and2.PNG)\r\n",
        "\r\n",
        "샘플 데이터 벡터를 소프트맥스 함수의 입력 벡터로 차원을 축소하는 방법은 간단하다. 소프트맥스 함수의 입력 벡터 z의 차원수만큼 결과값이 나오도록 가중치 곱을 진행한다. 위의 그림에서 화살표는 총 12개이며 전부 다른 가중치를 가지고, 학습 과정에서 점차적으로 오차를 최소화하는 가중치로 값이 변경된다.\r\n",
        "\r\n",
        "두번째 질문은 오차 계산 방법에 대한 질문이다. 소프트맥스 함수의 출력은 분류하고자하는 클래스의 개수만큼 차원을 가지는 벡터로 각 원소는 0과 1 사이의 값을 가진다. 이 각각은 특정 클래스가 정답일 확률을 나타낸다. 여기서는 첫 번째 원소인 p1 은 virginica가 정답일 확률, 두번째 원소인 p2는 setosa가 정답일 확률, 세 번째 원소인 p3는 versicolor가 정답일 확률이다. 그렇다면 이 예측값과 비교를 할 수 있는 실제값의 표현 방법이 있어야 하는데, 소프트맥스 회귀에서는 실제값을 원-핫 벡터로 표현한다.\r\n",
        "\r\n",
        "![대체 텍스트](https://wikidocs.net/images/page/35476/softmax2_final.PNG)\r\n",
        "\r\n",
        "위의 그림은 소프트맥스 함수의 출력 벡터의 첫번째 원소 p1가 virginica가 정답일 확률, 두번째 원소 p2가 setosa가 정답일 확률, 세 번째 원소 p3가 versicolor가 정답일 확률을 의미한다고 하였을 때, 각 실제값의 정수 인코딩은 1,2,3 이 되고 이에 원-핫 인코딩을 수행하여 실제값을 원-핫 벡터로 수치화한 것을 보여준다.\r\n",
        "\r\n",
        "![대체 텍스트](https://wikidocs.net/images/page/35476/softmax4.PNG)\r\n",
        "\r\n",
        "예를 들어 현재 풀고 있는 샘플 데이터의 실제값이 setosa 라면 setosa의 원-핫 벡터는 [0 1 0] 이 된다. 이 경우, 예측값과 실제값의 오차가 0이 되는 경우는 소프트맥스 함수의 결과가 [0 1 0]이 되는 경우이다. 이 두 벡터의 오차를 계산하기 위해서 소프트맥스 회귀는 비용 함수로 크로스 엔트로피 함수를 사용하는데, 이는 뒤에서 다시 설명\r\n",
        "\r\n",
        "![대체 텍스트](https://wikidocs.net/images/page/35476/softmax5.PNG)\r\n",
        "\r\n",
        "이제 앞서 배운 선형 회귀나 로지스틱 회귀와 같이 오차로부터 가중치를 업데이트 한다.\r\n",
        "\r\n",
        "![대체 텍스트](https://wikidocs.net/images/page/35476/softmax6_final.PNG)\r\n",
        "\r\n",
        "편향 또한 업데이트 되는 매개 변수이다. 소프트맥스 회귀를 벡터와 행렬 연산으로 이해해보자. 입력을 특성(feature) 수만큼 차원을 가진 입력 벡터 x라고 하고, 가중치 행렬을 W 편향을 b 라고 했을때, 소프트맥스 회귀에서 예측값을 구하는 과정을 벡터와 행렬 연산으로 표현하면 아래와 같다.\r\n",
        "\r\n",
        "\r\n",
        "![대체 텍스트](https://wikidocs.net/images/page/59427/%EA%B0%80%EC%84%A4.PNG)\r\n",
        "\r\n",
        "여기서 f는 특성의 수이며, c 는 클래스의 개수에 해당된다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fjO_arx56dH0"
      },
      "source": [
        "### 4.2.3 붓꽃 품종 분류하기 행렬 연산으로 이해하기\r\n",
        "\r\n",
        "위의 붓꽃 품종 분류 문제의 가설식을 행렬 연산으로 표현해보자. 우선 위의 예제의 데이터는 전체 샘플의 개수가 5개, 특성이 4개이므로, 5x4 행렬 X로 정의한다.\r\n",
        "\r\n",
        "$X=\r\n",
        "\\left(\r\n",
        "    \\begin{array}{c}\r\n",
        "      5.1\\ 3.5\\ 1.4\\ 0.2\\ \\\\\r\n",
        "      4.9\\ 3.0\\ 1.4\\ 0.2\\ \\\\\r\n",
        "      5.8\\ 2.6\\ 4.0\\ 1.2\\ \\\\\r\n",
        "      6.7\\ 3.0\\ 5.2\\ 2.3\\ \\\\\r\n",
        "      5.6\\ 2.8\\ 4.9\\ 2.0\\ \\\\\r\n",
        "    \\end{array}\r\n",
        "  \\right)$\r\n",
        "\r\n",
        "  편의를 위해 각 행렬의 원소 위치를 반영한 변수로 표현\r\n",
        "\r\n",
        "  $X=\\left(\r\n",
        "    \\begin{array}{c}\r\n",
        "      x_{11}\\ x_{12}\\ x_{13}\\ x_{14}\\ \\\\\r\n",
        "      x_{21}\\ x_{22}\\ x_{23}\\ x_{24}\\ \\\\\r\n",
        "      x_{31}\\ x_{32}\\ x_{33}\\ x_{34}\\ \\\\\r\n",
        "      x_{41}\\ x_{42}\\ x_{43}\\ x_{44}\\ \\\\\r\n",
        "      x_{51}\\ x_{52}\\ x_{53}\\ x_{54}\\ \\\\\r\n",
        "    \\end{array}\r\n",
        "  \\right)$\r\n",
        "\r\n",
        "  이번 문제는 선택지가 총 3개인 문제이므로 가설의 예측값으로 얻는 행렬$\\hat{Y}$의 열의 개수는 3개여야 한다. 그리고 각 행은 X의 각 행의 예측값이므로 행의 크기는 동일해야 한다. 결과적으로 행렬 $\\hat{Y}$의 크기는 5X3 이다.\r\n",
        "\r\n",
        "  $\\hat{Y}=\\left(\r\n",
        "    \\begin{array}{c}\r\n",
        "      y_{11}\\ y_{12}\\ y_{13}\\ \\\\\r\n",
        "      y_{21}\\ y_{22}\\ y_{23}\\ \\\\\r\n",
        "      y_{31}\\ y_{32}\\ y_{33}\\ \\\\\r\n",
        "      y_{41}\\ y_{42}\\ y_{43}\\ \\\\\r\n",
        "      y_{51}\\ y_{52}\\ y_{53}\\ \\\\\r\n",
        "    \\end{array}\r\n",
        "  \\right)$\r\n",
        "\r\n",
        "크기 5x3 Y헷 는 크기 5x4 입력 행렬 X 과 가중치 행렬 W의 곱으로 얻어지는 행렬이므로 가중치 행렬 W 의 크기는 추정을 통해 4x3 행렬임을 알 수 있다.\r\n",
        "\r\n",
        "$W=\\left(\r\n",
        "    \\begin{array}{c}\r\n",
        "      w_{11}\\ w_{12}\\ w_{13}\\ \\\\\r\n",
        "      w_{21}\\ w_{22}\\ w_{23}\\ \\\\\r\n",
        "      w_{31}\\ w_{32}\\ w_{33}\\ \\\\\r\n",
        "      w_{41}\\ w_{42}\\ w_{43}\\ \\\\\r\n",
        "    \\end{array}\r\n",
        "  \\right)$\r\n",
        "\r\n",
        "편향 행렬 B는 예측값 행렬 Y헷 과 크기가 동일해야 하므로 5X3의 크기를 가진다.\r\n",
        "\r\n",
        "$B=\\left(\r\n",
        "    \\begin{array}{c}\r\n",
        "      b_{1}\\ b_{2}\\ b_{3}\\\\\r\n",
        "      b_{1}\\ b_{2}\\ b_{3}\\\\\r\n",
        "      b_{1}\\ b_{2}\\ b_{3}\\\\\r\n",
        "      b_{1}\\ b_{2}\\ b_{3}\\\\\r\n",
        "      b_{1}\\ b_{2}\\ b_{3}\\\\\r\n",
        "    \\end{array}\r\n",
        "  \\right)$\r\n",
        "\r\n",
        "  결과적으로 가설식은 다음과 같다.\r\n",
        "\r\n",
        "  \r\n",
        "$\\hat{Y} = softmax(XW + B)$\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "$\\left(\r\n",
        "    \\begin{array}{c}\r\n",
        "      y_{11}\\ y_{12}\\ y_{13}\\ \\\\\r\n",
        "      y_{21}\\ y_{22}\\ y_{23}\\ \\\\\r\n",
        "      y_{31}\\ y_{32}\\ y_{33}\\ \\\\\r\n",
        "      y_{41}\\ y_{42}\\ y_{43}\\ \\\\\r\n",
        "      y_{51}\\ y_{52}\\ y_{53}\\ \\\\\r\n",
        "    \\end{array}\r\n",
        "  \\right)$=$softmax\\left(\r\n",
        "\\left(\r\n",
        "    \\begin{array}{c}\r\n",
        "      x_{11}\\ x_{12}\\ x_{13}\\ x_{14}\\ \\\\\r\n",
        "      x_{21}\\ x_{22}\\ x_{23}\\ x_{24}\\ \\\\\r\n",
        "      x_{31}\\ x_{32}\\ x_{33}\\ x_{34}\\ \\\\\r\n",
        "      x_{41}\\ x_{42}\\ x_{43}\\ x_{44}\\ \\\\\r\n",
        "      x_{51}\\ x_{52}\\ x_{53}\\ x_{54}\\ \\\\\r\n",
        "    \\end{array}\r\n",
        "  \\right)\r\n",
        "\\left(\r\n",
        "    \\begin{array}{c}\r\n",
        "      w_{11}\\ w_{12}\\ w_{13}\\ \\\\\r\n",
        "      w_{21}\\ w_{22}\\ w_{23}\\ \\\\\r\n",
        "      w_{31}\\ w_{32}\\ w_{33}\\ \\\\\r\n",
        "      w_{41}\\ w_{42}\\ w_{43}\\ \\\\\r\n",
        "    \\end{array}\r\n",
        "  \\right)\r\n",
        "+\r\n",
        "\\left(\r\n",
        "    \\begin{array}{c}\r\n",
        "      b_{1}\\ b_{2}\\ b_{3}\\\\\r\n",
        "      b_{1}\\ b_{2}\\ b_{3}\\\\\r\n",
        "      b_{1}\\ b_{2}\\ b_{3}\\\\\r\n",
        "      b_{1}\\ b_{2}\\ b_{3}\\\\\r\n",
        "      b_{1}\\ b_{2}\\ b_{3}\\\\\r\n",
        "    \\end{array}\r\n",
        "  \\right)\r\n",
        "\\right)$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yBHhWmyS7cEA"
      },
      "source": [
        "### 4.2.4 비용 함수 (cost fuction)\r\n",
        "\r\n",
        "소프트맥스 회귀에서는 비용 함수로 크로스 엔트로피 함수를 사용한다. 여기서는 소프트맥스 회귀에서의 크로스 엔트로피 함수뿐만 아니라, 다양한 표기 방법에 대해서 이해해보겠다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YJcSPlXm7nOI"
      },
      "source": [
        "1) 크로스 엔트로피 함수\r\n",
        "\r\n",
        "아래에서 y는 실제값을 나타내며, k는 클래스의 개수로 정의한다. yj는 실제값 원-핫 벡터의 j번째 index를 의미하며, pj는 샘플 데이터가 j번째 클래스일 확률을 나타낸다. 표기에 따라서 $\\hat{y}_{j}$ 로 표현하기도 한다.\r\n",
        "\r\n",
        "$cost(W) = -\\sum_{j=1}^{k}y_{j}\\ log(p_{j})$\r\n",
        "\r\n",
        "이 함수과 왜 비용함 수로 적합한가? c가 실제값 원-핫 벡터에서 1을 가진 원소의 인덱스라고 한다면 , $p_{c}=1$은 $\\hat{y}$가 $y$를 정확하게 예측한 경우가 된다. 이를 식에 대입해보면  $-1 log(1) = 0$이 되기 때문에 결과적으로 y헷 가 y를 정확하게 예측한 경우의 크로스 엔트로피 값은 0이 된다. $-\\sum_{j=1}^{k}y_{j}\\ log(p_{j})$이 값을 최소화하는  방향으로 학습해야한다는 뜻임\r\n",
        "\r\n",
        "이제 이를 n개의 전체 데이터에 대한 평균을 구한다고 한다면 최종 비용 함수는 다음과 같다.\r\n",
        "\r\n",
        "\r\n",
        "$cost(W) = -\\frac{1}{n} \\sum_{i=1}^{n} \\sum_{j=1}^{k}y_{j}^{(i)}\\ log(p_{j}^{(i)})$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F8ZY_r9L8Txe"
      },
      "source": [
        "2) 이진 분류에서의 크로스 엔트로피 함수\r\n",
        "\r\n",
        "로지스틱 회귀에서 배운 크로스 엔트로피 함수식과 달라보이지만, 본질적으로는 동일한 함수식이다. 로지스틱 회귀의 크로스 엔트로피 함수식으로부터 소프트맥스 회귀의 크로스 엔트로피 함수식을 도출해보자.\r\n",
        "\r\n",
        "$cost(W) = -(y\\ logH(X) + (1-y)\\ log(1-H(X)))$\r\n",
        "\r\n",
        "위의 식은 앞서 로지스틱 회귀에서 배웠던 크로스 엔트로피의 함수식을 보여준다. 위의 식에서 $y$를 $y_1$, $y$−1을 $y_2$로 치환하고 $H(X)$를 $p_1$, 1−$H(X)$를 $p_2$로 치환해보자.\r\n",
        "결과적으로 아래의 식이 나온다.\r\n",
        "\r\n",
        "$-(y_{1}\\ log(p_{1})+y_{2}\\ log(p_{2}))$\r\n",
        "\r\n",
        "이 식은 아래와 같이 표현할 수 있다.\r\n",
        "\r\n",
        "$-(\\sum_{i=1}^{2}y_{i}\\ log\\ p_{i})$\r\n",
        "\r\n",
        "소프트맥스 회귀에서는 k의 값이 고정된 값이 아니므로 2를 k로 변경한다.\r\n",
        "\r\n",
        "$-(\\sum_{i=1}^{k}y_{i}\\ log\\ p_{i})$\r\n",
        "\r\n",
        "위의 식은 결과적으로 소프트맥스 회귀의 식과 동일하다.\r\n",
        "역으로 소프트맥스 회귀에서 로지스틱 회귀의 크로스 엔트로피 함수식을 얻는 것은 k를 2로 하고, y1 , y2 를 각각 y와 1-y로 바꾸고, p1,p2를 각각 H(x) 와 1-H(x)로 치환하면 된다.\r\n",
        "\r\n",
        "정리하면 소프트맥스 함수의 최종 비용 함수에서 k가 2라고 가정하면 결국 로지스틱 회귀의 비용 함수와 같다.\r\n",
        "\r\n",
        "\r\n",
        "$cost(W) = -\\frac{1}{n} \\sum_{i=1}^{n} \\sum_{j=1}^{k}y_{j}^{(i)}\\ log(p_{j}^{(i)}) = -\\frac{1}{n} \\sum_{i=1}^{n} [y^{(i)}log(p^{(i)}) + (1-y^{(i)})log(1-p^{(i)})]$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uvfGTnMu9XP3"
      },
      "source": [
        "## 4.3 소프트맥스 회귀의 비용 함수 구현하기\r\n",
        "\r\n",
        "이번 챕터에서는 소프트맥스 회귀를 구현해보자\r\n",
        "\r\n",
        "앞으로의 모든 실습은 아래의 과정이 이미 진행되었다고 가정한다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H-GYg7bk9dWM",
        "outputId": "5cd0fae0-6146-46d5-f13e-415091a1affd"
      },
      "source": [
        "import torch\r\n",
        "import torch.nn.functional as F\r\n",
        "torch.manual_seed(1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7fc7cf783b70>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FIzz8OZl9gVK"
      },
      "source": [
        "### 4.3.1 파이토치로 소프트맥스의 비용 함수 구현하기(로우-레벨)\r\n",
        "\r\n",
        "소프트맥스 회귀를 구현함에 있어 우선 소프트맥스 함수의 비용 함수를 로우-레벨로 구현해보자. 3개의 원소를 가진 벡터 텐서를 정의하고, 이 텐서를 통해 소프트맥스 함수를 이해해보겠다.\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PjjT7jpP9t7H"
      },
      "source": [
        "z = torch.FloatTensor( [1,2,3])\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Iw1hTBn-9v9p",
        "outputId": "34ebf48d-0a03-474a-ed01-d0065ab98e6f"
      },
      "source": [
        "# 이 텐서를 소프트맥스의 함수의 입력으로 사용하고, 그 결과를 확인해보자\r\n",
        "\r\n",
        "hypothesis = F.softmax(z, dim=0)\r\n",
        "print(hypothesis)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([0.0900, 0.2447, 0.6652])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-CISMN0k91aV",
        "outputId": "a8c2913b-0423-4f06-ac74-366e1392ea79"
      },
      "source": [
        "# 3개의 원소의 값이 0과 1 사이를 가지는 벡터로 변환됐다. 이원소들의 값의 합이 1인가?\r\n",
        "hypothesis.sum()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(1.)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QjFbW_vD98Vm"
      },
      "source": [
        "# 총 원소의 값은 1이다. 이번에는 비용 함수를 직접 구현해본다. 임의의 3x5 행렬을 만든다.\r\n",
        "\r\n",
        "z = torch.rand(3,5, requires_grad=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eCf4OZTI-EhF",
        "outputId": "7dd56e0a-af35-4bde-b956-cc8e355bb4ac"
      },
      "source": [
        "# 이제 이 텐서에 대해 소프트맥스 함수를 적용한다. 단, 각 샘플에 대해서 소프트맥스 함수를 적용하여야 하므로\r\n",
        "# 두 번째 차원에 대해서 소프트맥스 함수를 적용한다는 의미로 dim = 1  을 써준다.\r\n",
        "\r\n",
        "hypothesis = F.softmax(z, dim=1)\r\n",
        "print(hypothesis)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[0.2645, 0.1639, 0.1855, 0.2585, 0.1277],\n",
            "        [0.2430, 0.1624, 0.2322, 0.1930, 0.1694],\n",
            "        [0.2226, 0.1986, 0.2326, 0.1594, 0.1868]], grad_fn=<SoftmaxBackward>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yl2nXWD2-U9D"
      },
      "source": [
        "이제 각 행의 원소들의 합은 1이 되는 텐서로 변환되었다. 소프트맥스 함수의 출력값은 결국 예측값이다. 즉, 위 텐서는 3개의 샘플에 대해서 5개의 클래스 중 어떤 클래스가 정답인지를 예측한 결과이다.\r\n",
        "\r\n",
        "이제 각 샘프에 대해 임의의 레이블을 만든다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lCMPs5dX-f9W",
        "outputId": "408436a0-8266-48f9-de2b-cf6986546464"
      },
      "source": [
        "y = torch.randint(5, (3,)).long()\r\n",
        "print(y)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([0, 2, 1])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tvr5rw54-jj7",
        "outputId": "4a16050d-f1ca-499a-ac36-b3cc971423a3"
      },
      "source": [
        "# 각 레이블에 대해 원-핫 인코딩을 수행한다.\r\n",
        "\r\n",
        "# 모든 원소가 0을 가진 3x5 텐서 생성\r\n",
        "\r\n",
        "y_one_hot = torch.zeros_like(hypothesis)\r\n",
        "y_one_hot.scatter_(1,y.unsqueeze(1), 1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1., 0., 0., 0., 0.],\n",
              "        [0., 0., 1., 0., 0.],\n",
              "        [0., 1., 0., 0., 0.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1nvhk_hU-4TU"
      },
      "source": [
        "위의 연산에서 어떻게 원-핫 인코딩이 수행되었는가? 우선 , torch.zeros_like(hypothesis)를 통해 모든 원소가 0이면서 hypothesis의 모양을 따르는 3x5 행렬을 만든다. 그리고 이 텐서는 y_one_hot에 할당됐다.\r\n",
        "\r\n",
        "두 번째 줄, y.unsqueeze(1) 를 하면 (3,)의 크기를 가졌던 y 텐서는 (3x1) 텐서가 된다. 즉 y.unsqueeze(1)의 결과는 다음과 같다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0UMeM8Gs_MPj",
        "outputId": "55f2ae2c-4f67-48e7-861f-7b8119174fe6"
      },
      "source": [
        "print(y.unsqueeze(1))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[0],\n",
            "        [2],\n",
            "        [1]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z4N5ZzKS_OVL"
      },
      "source": [
        "그리고 scatter의 첫 번째 인자로 dim=1 에 대해 수행하라고 알려주고, 세 번째 인자에 숫자 1을 넣어줘서 두 번째 인자인 y_unsqueeze(1) 이 알려주는 위치에 숫자 1을 넣도록 한다. 연산 뒤에 _를 붙이면 덮어쓰기 연산임을 배운 바 있다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EYHLX5HC_fRR",
        "outputId": "29f98cda-585b-4572-b590-70c8056ac308"
      },
      "source": [
        "print(y_one_hot)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[1., 0., 0., 0., 0.],\n",
            "        [0., 0., 1., 0., 0.],\n",
            "        [0., 1., 0., 0., 0.]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0iQUUqlX_gIg"
      },
      "source": [
        "이제 비용 함수 연산을 위한 재료들을 전부 손질했다. 소프트맥스 회귀의 비용 함수는 다음과 같았다.\r\n",
        "\r\n",
        "$cost(W) = -\\frac{1}{n} \\sum_{i=1}^{n} \\sum_{j=1}^{k}y_{j}^{(i)}\\ log(p_{j}^{(i)})$\r\n",
        "\r\n",
        "마이너스 부호를 뒤로 빼면 다음 식과도 동일하다.\r\n",
        "\r\n",
        "$cost(W) = \\frac{1}{n} \\sum_{i=1}^{n} \\sum_{j=1}^{k}y_{j}^{(i)}\\ * (-log(p_{j}^{(i)}))$\r\n",
        "\r\n",
        "이를 코드로 구현하면 아래와 같다.\r\n",
        "\r\n",
        "$\\sum_{j=1}^{k}$는 sum(dim=1)으로 구현하고, $\\frac{1}{n} \\sum_{i=1}^{n}$는 mean()으로 구현한다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4e9QlH4p_u-7"
      },
      "source": [
        "cost = (y_one_hot * -torch.log(hypothesis)).sum(dim=1).mean()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cqLNscI5_zzM",
        "outputId": "f7915d60-0627-4401-f05a-2535d1a4bbe5"
      },
      "source": [
        "print(cost)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(1.4689, grad_fn=<MeanBackward0>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6J24bO0a_0cZ"
      },
      "source": [
        "### 4.3.2 파이토치로 소프트맥스의 비용 함수 구현하기 (하이-레벨)\r\n",
        "\r\n",
        "이제 소프트맥스의 비용 함수를 좀 더 하이-레벨로 구현하는 방법에 대해 알아보자\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eRhtqd7S_7oR"
      },
      "source": [
        "1) F.softmax() + torch.log() = F.log_softmax()(\r\n",
        "\r\n",
        "  앞서 소프트맥스 함수의 결과에 로그를 씌울 때는 다음과 같이 소프트맥스 함수의 출력값을 로그 함수의 입력으로 사용했다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZHHWwZurADab",
        "outputId": "296693fc-de3f-40f3-c31b-c85567149d3e"
      },
      "source": [
        "# Low level\r\n",
        "\r\n",
        "torch.log(F.softmax(z,dim=1))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-1.3301, -1.8084, -1.6846, -1.3530, -2.0584],\n",
              "        [-1.4147, -1.8174, -1.4602, -1.6450, -1.7758],\n",
              "        [-1.5025, -1.6165, -1.4586, -1.8360, -1.6776]], grad_fn=<LogBackward>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HDqvWTGgAGl4",
        "outputId": "d7b25e56-08dd-4990-8662-e8274100bf52"
      },
      "source": [
        "# High level\r\n",
        "\r\n",
        "F.log_softmax(z, dim= 1)  # 두 개의 함수를 결합한 F.log_softmax() 라는 도구를 제공한다."
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-1.3301, -1.8084, -1.6846, -1.3530, -2.0584],\n",
              "        [-1.4147, -1.8174, -1.4602, -1.6450, -1.7758],\n",
              "        [-1.5025, -1.6165, -1.4586, -1.8360, -1.6776]],\n",
              "       grad_fn=<LogSoftmaxBackward>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J1uY44Z0APbr"
      },
      "source": [
        "2) F.log_softmax() + F.nll_loss() = F.cross_entropy()\r\n",
        "\r\n",
        "앞서 로우- 레벨로 구현한 비용 함수는 다음과 같았다.\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TUmyoxPBAWtT",
        "outputId": "56261a80-7ccf-4aa8-c03d-9ae966c8d870"
      },
      "source": [
        "# low level\r\n",
        "# 첫 번째 수식\r\n",
        "\r\n",
        "(y_one_hot * -torch.log(F.softmax(z, dim=1))).sum(dim=1).mean()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(1.4689, grad_fn=<MeanBackward0>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CuX_W0YNAdnk",
        "outputId": "013d76ce-cc9a-4acc-fe07-855fdd045eb0"
      },
      "source": [
        "# F.log_softmax() 로 대체할 수 있다.\r\n",
        "\r\n",
        "# 두 번째 수식\r\n",
        "\r\n",
        "(y_one_hot * - F.log_softmax(z, dim=1)).sum(dim=1).mean()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(1.4689, grad_fn=<MeanBackward0>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o5R4quUSAoKr"
      },
      "source": [
        "이를 더 간단하게 하면 다음과 같다. F.nll_loss()를 사용 할 때는 바로 실제값을 인자로 사용한다. *원-핫 벡터를 넣을 필요가 없다!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wa7-JvtOAsTD",
        "outputId": "4ac57a5f-341b-481c-e7e9-3f5f2a7fb975"
      },
      "source": [
        "# High level\r\n",
        "\r\n",
        "# 세 번째 수식\r\n",
        "\r\n",
        "F.nll_loss(F.log_softmax(z, dim=1 ) ,y)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(1.4689, grad_fn=<NllLossBackward>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MnWwWz2BAw7x"
      },
      "source": [
        "여기서 nll 이란 Negative Log Likelihood의 약자이다. 위에서 nll_loss 는 F.log_softmax() 를 수행한 후에 남은 수식들을 수행한다. 이를 더 간단하게 하면 다음과 같이 사용할 수도 있다. F.cross_entropy() 는 F.log_softmax()와 F.nll_loss()를 포함하고 있다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yFdDPKxxBHhc",
        "outputId": "c261bd92-666e-4c6b-9669-f76925770a52"
      },
      "source": [
        "# 네 번째 수식\r\n",
        "\r\n",
        "F.cross_entropy(z, y)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(1.4689, grad_fn=<NllLossBackward>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vKrBsuruBJsq"
      },
      "source": [
        "F.cross_entorpy 는 비용 함수에 소프트맥스 함수까지 포함하고 있음을 기억해야 구현 시 혼동하지 않는다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8qJHoTyiBPMI"
      },
      "source": [
        "## 4.4 소프트맥스 회귀 구현하기\r\n",
        "\r\n",
        "소프트맥스 회귀를 로우-레벨과 F.cross_entropy를 사용해서 구현해보겠다. 앞으로의 모든 실습은 아래의 과정이 이미 진행되었다고 가정한다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9tJBHrQbBa3H"
      },
      "source": [
        "import torch\r\n",
        "import torch.nn as nn\r\n",
        "import torch.nn.functional as F\r\n",
        "import torch.optim as optim"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M2xxdf17BfmQ"
      },
      "source": [
        "x_train = [[1, 2, 1, 1],\r\n",
        "           [2, 1, 3, 2],\r\n",
        "           [3, 1, 3, 4],\r\n",
        "           [4, 1, 5, 5],\r\n",
        "           [1, 7, 5, 5],\r\n",
        "           [1, 2, 5, 6],\r\n",
        "           [1, 6, 6, 6],\r\n",
        "           [1, 7, 7, 7]]\r\n",
        "y_train = [2, 2, 2, 1, 1, 1, 0, 0]\r\n",
        "x_train = torch.FloatTensor(x_train)\r\n",
        "y_train = torch.LongTensor(y_train)\r\n",
        "\r\n",
        "# x_train 의 각 샘플을 4개의 특성을 가지고 있고, 8개의 샘플이 있다.\r\n",
        "# y_train은 각 샘플에 대한 레이블인데, 여기서는 0,1,2 의 값을 가지는 걸 보아 3개의 클래스가 존재한다."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jxk-Hq49BuS8"
      },
      "source": [
        "### 4.4.1 소프트맥스 회귀 구현하기 (로우-레벨)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZEVSH50OBxBo",
        "outputId": "801f06c3-5c11-4711-be52-65d2b8f25802"
      },
      "source": [
        "# x_train과 y_train의 크기를 확인\r\n",
        "\r\n",
        "print(x_train.shape)\r\n",
        "print(y_train.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([8, 4])\n",
            "torch.Size([8])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VNex7V2zB2jn",
        "outputId": "57844178-a0d4-4147-848c-2d7d2248c4a9"
      },
      "source": [
        "# x_train의 크기는 8x4 이며, y_train의 크기는 8x1 이다. 최종 사용할 레이블은 y_train에서 원-핫 인코딩을 한결과이므로\r\n",
        "# 클래스의 개수가 3개이므로, y_train에 원-핫 인코딩을 한 결과는 8x3 의 개수를 가져야 한다.\r\n",
        "\r\n",
        "y_one_hot = torch.zeros(8,3)\r\n",
        "y_one_hot.scatter_(1, y_train.unsqueeze(1), 1)\r\n",
        "print(y_one_hot.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([8, 3])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cXDvUZY6CNPW"
      },
      "source": [
        "# y_train에서 원-핫 인코딩을 한 결과인 y_one_hot의 크기는 8x3 이다. 즉, W행렬의 크기는 4x3이어야 한다.\r\n",
        "# W와 b를 선언하고 , 옵티마이저는 SGD를 사용한다. lr = 0.1\r\n",
        "\r\n",
        "# 모델 초기화\r\n",
        "\r\n",
        "W = torch.zeros((4,3), requires_grad=True)\r\n",
        "b = torch.zeros(1, requires_grad=True)\r\n",
        "\r\n",
        "# optimizer 설정\r\n",
        "\r\n",
        "optimizer = optim.SGD([W,b], lr = 0.1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kl6s-W6jCjff",
        "outputId": "62e3ea3c-ac60-4f37-c26d-3e5f373c553a"
      },
      "source": [
        "nb_epochs = 1000\r\n",
        "for epoch in range(nb_epochs + 1):\r\n",
        "\r\n",
        "    # 가설\r\n",
        "    hypothesis = F.softmax(x_train.matmul(W) + b, dim=1) \r\n",
        "\r\n",
        "    # 비용 함수\r\n",
        "    cost = (y_one_hot * -torch.log(hypothesis)).sum(dim=1).mean()\r\n",
        "\r\n",
        "    # cost로 H(x) 개선\r\n",
        "    optimizer.zero_grad()\r\n",
        "    cost.backward()\r\n",
        "    optimizer.step()\r\n",
        "\r\n",
        "    # 100번마다 로그 출력\r\n",
        "    if epoch % 100 == 0:\r\n",
        "        print('Epoch {:4d}/{} Cost: {:.6f}'.format(\r\n",
        "            epoch, nb_epochs, cost.item()\r\n",
        "        ))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch    0/1000 Cost: 1.098612\n",
            "Epoch  100/1000 Cost: 0.761050\n",
            "Epoch  200/1000 Cost: 0.689991\n",
            "Epoch  300/1000 Cost: 0.643229\n",
            "Epoch  400/1000 Cost: 0.604117\n",
            "Epoch  500/1000 Cost: 0.568255\n",
            "Epoch  600/1000 Cost: 0.533922\n",
            "Epoch  700/1000 Cost: 0.500291\n",
            "Epoch  800/1000 Cost: 0.466908\n",
            "Epoch  900/1000 Cost: 0.433507\n",
            "Epoch 1000/1000 Cost: 0.399962\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qIlMcv3ACp53"
      },
      "source": [
        "### 4.4.2 소프트맥스 회귀 구현하기(하이-레벨)\r\n",
        "\r\n",
        "이제는 F.cross_entropy()를 사용하여 비용 함수를 구현해보겠다. 주의할 점은 F.cross_entropy() 는 그 자체로 소프트맥스함수를 포함하고 있으므로 가설에서 소프트맥스를 사용할 필요가 없다.\r\n",
        "\r\n",
        "위와 동일한 x_train, y_train을 사용.\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6M4Ce-d4rpFe",
        "outputId": "54392222-f391-4095-b9f4-cdf605686685"
      },
      "source": [
        "# 모델 초기화\r\n",
        "\r\n",
        "W = torch.zeros((4,3), requires_grad=True)\r\n",
        "b = torch.zeros(1, requires_grad=True)\r\n",
        "\r\n",
        "# optimizer 설정\r\n",
        "\r\n",
        "optimizer = optim.SGD([W,b], lr = 0.1)\r\n",
        "\r\n",
        "nb_epochs = 1000\r\n",
        "\r\n",
        "for epoch in range(nb_epochs+1):\r\n",
        "  # Cost\r\n",
        "  z= x_train.matmul(W)+b\r\n",
        "  cost = F.cross_entropy(z, y_train)\r\n",
        "\r\n",
        "  # cost 로 H(x) 개선\r\n",
        "  optimizer.zero_grad()\r\n",
        "  cost.backward()\r\n",
        "  optimizer.step()\r\n",
        "\r\n",
        "  # 100번마다 로그 출력\r\n",
        "  if epoch % 100 == 0:\r\n",
        "      print('Epoch {:4d}/{} Cost: {:.6f}'.format(\r\n",
        "          epoch, nb_epochs, cost.item()\r\n",
        "          ))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch    0/1000 Cost: 1.098612\n",
            "Epoch  100/1000 Cost: 0.761050\n",
            "Epoch  200/1000 Cost: 0.689991\n",
            "Epoch  300/1000 Cost: 0.643229\n",
            "Epoch  400/1000 Cost: 0.604117\n",
            "Epoch  500/1000 Cost: 0.568256\n",
            "Epoch  600/1000 Cost: 0.533922\n",
            "Epoch  700/1000 Cost: 0.500291\n",
            "Epoch  800/1000 Cost: 0.466908\n",
            "Epoch  900/1000 Cost: 0.433507\n",
            "Epoch 1000/1000 Cost: 0.399962\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JIELfiicsEEi"
      },
      "source": [
        "### 4.4.3 소프트맥스 회귀 nn.Module로 구현하기\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v-ghnQMpsN6X"
      },
      "source": [
        "# 모델을 선언 및 초기화. 4개의 특성 3개의 클래스 분류 input_dim = 4, output_dim =3\r\n",
        "model = nn.Linear(4,3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BfdhEusPsUvm",
        "outputId": "8ef8689d-9e11-41b9-cc79-6fb49907d8c3"
      },
      "source": [
        "# optimizer 설정\r\n",
        "\r\n",
        "optimizer=optim.SGD(model.parameters(), lr = 0.1)\r\n",
        "\r\n",
        "nb_epochs = 1000\r\n",
        "\r\n",
        "for epoch in range(nb_epochs+1):\r\n",
        "\r\n",
        "  # H(x)\r\n",
        "  prediction = model(x_train)\r\n",
        "\r\n",
        "  # cost\r\n",
        "  cost = F.cross_entropy(prediction,y_train)\r\n",
        "\r\n",
        "  # cost로 H(x) 개선\r\n",
        "  optimizer.zero_grad()\r\n",
        "  cost.backward()\r\n",
        "  optimizer.step()\r\n",
        "\r\n",
        "  # 20번마다 로그 출력\r\n",
        "  if epoch % 100 == 0:\r\n",
        "        print('Epoch {:4d}/{} Cost: {:.6f}'.format(\r\n",
        "            epoch, nb_epochs, cost.item()\r\n",
        "        ))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch    0/1000 Cost: 1.849513\n",
            "Epoch  100/1000 Cost: 0.689894\n",
            "Epoch  200/1000 Cost: 0.609259\n",
            "Epoch  300/1000 Cost: 0.551218\n",
            "Epoch  400/1000 Cost: 0.500141\n",
            "Epoch  500/1000 Cost: 0.451947\n",
            "Epoch  600/1000 Cost: 0.405051\n",
            "Epoch  700/1000 Cost: 0.358733\n",
            "Epoch  800/1000 Cost: 0.312912\n",
            "Epoch  900/1000 Cost: 0.269522\n",
            "Epoch 1000/1000 Cost: 0.241922\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_qETo6uyssoa"
      },
      "source": [
        "### 4.4.4 소프트맥스 회귀 클래스로 구현하기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L5LT09J7tIRz"
      },
      "source": [
        "class SoftmaxClassifierModel(nn.Module):\r\n",
        "  def __init__(self):\r\n",
        "    super().__init__()\r\n",
        "    self.linear = nn.Linear(4,3) # ouput = 3\r\n",
        "\r\n",
        "  def forward(self, x):\r\n",
        "    return self.linear(x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VTqkRRAttYgF"
      },
      "source": [
        "model = SoftmaxClassifierModel()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_GbVeRR_taO7",
        "outputId": "283ea165-4de7-4485-9837-3a8fce23fe7c"
      },
      "source": [
        "# optimizer 설정\r\n",
        "\r\n",
        "optimizer = optim.SGD(model.parameters(),lr= 0.1)\r\n",
        "\r\n",
        "\r\n",
        "nb_epochs = 1000\r\n",
        "\r\n",
        "for epoch in range(nb_epochs+1):\r\n",
        "\r\n",
        "  # H(x)\r\n",
        "  prediction = model(x_train)\r\n",
        "\r\n",
        "  # cost\r\n",
        "  cost = F.cross_entropy(prediction,y_train)\r\n",
        "\r\n",
        "  # cost로 H(x) 개선\r\n",
        "  optimizer.zero_grad()\r\n",
        "  cost.backward()\r\n",
        "  optimizer.step()\r\n",
        "\r\n",
        "  # 20번마다 로그 출력\r\n",
        "  if epoch % 100 == 0:\r\n",
        "        print('Epoch {:4d}/{} Cost: {:.6f}'.format(\r\n",
        "            epoch, nb_epochs, cost.item()\r\n",
        "        ))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch    0/1000 Cost: 1.845720\n",
            "Epoch  100/1000 Cost: 0.647150\n",
            "Epoch  200/1000 Cost: 0.568868\n",
            "Epoch  300/1000 Cost: 0.515699\n",
            "Epoch  400/1000 Cost: 0.471727\n",
            "Epoch  500/1000 Cost: 0.432486\n",
            "Epoch  600/1000 Cost: 0.395879\n",
            "Epoch  700/1000 Cost: 0.360507\n",
            "Epoch  800/1000 Cost: 0.325227\n",
            "Epoch  900/1000 Cost: 0.289217\n",
            "Epoch 1000/1000 Cost: 0.254086\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cBxFq5rotrqg"
      },
      "source": [
        "## 4.5 소프트맥스 회귀로 MNIST 데이터 분류하기"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YlvIp7SYtu7U"
      },
      "source": [
        "### 4.5.1 MNIST 데이터 이해하기\r\n",
        "\r\n",
        "![대체 텍스트](https://wikidocs.net/images/page/60324/mnist.png)\r\n",
        "\r\n",
        "\r\n",
        "MNIST 는 숫자 0부터 9까지의 이미지로 구성된 손글씨 데이터셋이다. 이 데이터는 과거에 우체국에서 편지의 우편번호를 인식하기 위해서 만들어진 훈련 데이터이다. 총 60,000개의 훈련데이터와 레이블, 총 10000개의 테스트 데이터와 레이블이 있다. 이 예제는 머신 러닝을 처음 배울 때 접하게 되는 가장 기본적인 예제다.\r\n",
        "\r\n",
        "MNIST 문제는 손글씨로 적힌 숫자 이미지가 들어오면, 그 이미지가 무슨 숫자인지 맞추는 문제이다. 예를 들어 숫자 5의 이미지가 입력으로 들어오면 이게 숫자 5다 라는 것을 맞춰야 한다. 이 문제는 사람에게 간단하지만 기계에게는 그렇지 않다.\r\n",
        "\r\n",
        "우선 MNIST 문제를 더 자세히 보면 각각의 이미지는 아래와 같이 28x28 픽세르이 이미지다.\r\n",
        "\r\n",
        "![대체 텍스트](https://wikidocs.net/images/page/60324/mnist_SVbcYYG.png)\r\n",
        "\r\n",
        "이 문제를 풀기 위해 여기서는 28x28 픽셀 = 784 픽셀이므로 각 이미지를 총 784 개의 원소를 가진 벡터로 만들어 줄거다. 이렇게 되면 총 784 개의 특성을 가진 샘플이 되는데, 이는 앞서 우리가 풀었던 그 어떤 문제들보다 특성이 굉장히 많다\r\n",
        "\r\n",
        "\r\n",
        "![대체 텍스트](https://wikidocs.net/images/page/60324/%EB%8B%A4%EC%9A%B4%EB%A1%9C%EB%93%9C.png)\r\n",
        "\r\n",
        "784 차원의 벡터로 만드는 코드를 미리보기로 보면 다음과 같다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6XbfwwVjuYUb"
      },
      "source": [
        "import torch\r\n",
        "import torchvision.datasets as dsets\r\n",
        "import torchvision.transforms as transforms\r\n",
        "from torch.utils.data import DataLoader\r\n",
        "import torch.nn as nn\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "import random"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 399,
          "referenced_widgets": [
            "693f6203656845cf9fa3168f7d1dce3d",
            "f1a06a79be5d4061b1dfc310bc7bdd82",
            "3f23203da5ba4c2fb972583f3e8081ee",
            "cbe3cf628c8b422b85dee2f829073bd3",
            "df758e1bbefb4a9a8a4c9ac82f06e818",
            "99fef8f4ef474af197314e6a3a13ff71",
            "510c7ce760f4421db97c9640fb939fe2",
            "e0efc2c9d159482fbf16cc0e67ab29e0",
            "493ce21d0798448a8753eee4562e16fd",
            "4acec282f9894f67af0101ceee42015e",
            "311faeed821a4195bdda4d9c0b8edbc7",
            "326e3389a3ae44d1a28ebb1e712877f8",
            "b10a2af961ab4896892ce9de593790de",
            "cf144e214ee448848bd0c02582100097",
            "d2a8fcf15b434f3baa46b419cf47ea97",
            "56464e935572456da5fd1e6d8a72dc6c",
            "714e23d021bb4dbf8b629506df88de51",
            "2ebacef163bb4be6991156425c59683e",
            "212dcc6212d6430d9ba5cdeb81ab9e3f",
            "28d7bcc4aafa45ff826065d24d1cb159",
            "bd0575fca92a401a96295924f85ded2f",
            "11c71dc1784542ff8e2245346931a468",
            "5962701d113f471f8b031106fd02d2e4",
            "5f799bf348014204ba9c46953a314ea9",
            "8a9a1e37adca49529b8d50f999fe3fda",
            "01872a52096242c6bfc188b392da086e",
            "ed0463892ba0496cb139a9285860cf8a",
            "bff971b14fd7491a85424e1a7b6260ba",
            "da3f26497d9643d2999ce94f5aa0122c",
            "4e4296cb8eb648ff9e628228faa992f3",
            "5cd808865e024663b532507e26b0135f",
            "e47cd5d9bbb943a8927b129c79e424b3"
          ]
        },
        "id": "siFf0nhOulZH",
        "outputId": "d383a635-f9c1-45d9-b563-e314b7d1d21a"
      },
      "source": [
        "# MNIST dataset\r\n",
        "# 자세한 건 후술\r\n",
        "\r\n",
        "mnist_train = dsets.MNIST(root='MNIST_data/',\r\n",
        "                          train=True,\r\n",
        "                          transform=transforms.ToTensor(),\r\n",
        "                          download=True)\r\n",
        "\r\n",
        "mnist_test = dsets.MNIST(root='MNIST_data/',\r\n",
        "                         train=False,\r\n",
        "                         transform=transforms.ToTensor(),\r\n",
        "                         download=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to MNIST_data/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "693f6203656845cf9fa3168f7d1dce3d",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting MNIST_data/MNIST/raw/train-images-idx3-ubyte.gz to MNIST_data/MNIST/raw\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to MNIST_data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "493ce21d0798448a8753eee4562e16fd",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting MNIST_data/MNIST/raw/train-labels-idx1-ubyte.gz to MNIST_data/MNIST/raw\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to MNIST_data/MNIST/raw/t10k-images-idx3-ubyte.gz\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "714e23d021bb4dbf8b629506df88de51",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting MNIST_data/MNIST/raw/t10k-images-idx3-ubyte.gz to MNIST_data/MNIST/raw\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to MNIST_data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8a9a1e37adca49529b8d50f999fe3fda",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting MNIST_data/MNIST/raw/t10k-labels-idx1-ubyte.gz to MNIST_data/MNIST/raw\n",
            "Processing...\n",
            "Done!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torchvision/datasets/mnist.py:480: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /pytorch/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
            "  return torch.from_numpy(parsed.astype(m[2], copy=False)).view(*s)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HSOH1J1Qu7r0",
        "outputId": "d3e7d24a-46da-43e0-adb6-50c6aa606045"
      },
      "source": [
        "X,y = mnist_train[0]\r\n",
        "print('X size = ',X.size())\r\n",
        "print('입력 이미지를 [batch_size X 784]의 크기로 reshape = ',X.view(-1, 28*28).size())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "X size =  torch.Size([1, 28, 28])\n",
            "입력 이미지를 [batch_size X 784]의 크기로 reshape =  torch.Size([1, 784])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kye5-pWJvSJl"
      },
      "source": [
        "### 4.5.2 토치비젼 소개하기\r\n",
        "\r\n",
        "본격적인 실습에 앞서 토치비젼이라는 도구에 대해 설명해보자. torchvision은 유명한 데이터셋들, 이미 구현되어져 있는 유명한 모델들, 일반적인 이미지 전처리 도구들을 포함하고 있는 패키지이다. 아래의 링크는 torchvision 에 어떤 데이터셋들, 어떤 모델들 그리고 전처리 방법들 (datasets, models, transfomrs) 을 제공하고 있는지 보여준다\r\n",
        "\r\n",
        "링크 : https://pytorch.org/docs/stable/torchvision/index.html\r\n",
        "\r\n",
        "자연어 처리를 위해서는 torchtext 라는 패키지가 있다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WSHCMPxFvlWL"
      },
      "source": [
        "### 4.5.3 분류기 구현을 위한 사전 설정\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pucHQsk5wBEr",
        "outputId": "ba16d43a-b58c-4393-fb29-c66c3d870580"
      },
      "source": [
        "USE_CUDA = torch.cuda.is_available() # GPU 사용 가능하면 True, 아니라면 False 를 리턴\r\n",
        "device = torch.device('cuda' if USE_CUDA else 'cpu') # GPU 사용 가능하면 사용하고 아니면 cpu 사용\r\n",
        "\r\n",
        "print('다음 기기로 학습합니다',device)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "다음 기기로 학습합니다 cuda\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VQKg09OSwOMy"
      },
      "source": [
        "# for reproducibility\r\n",
        "\r\n",
        "random.seed(777)\r\n",
        "torch.manual_seed(777)\r\n",
        "if device == 'cuda':\r\n",
        "  torch.cuda.manual_seed_all(777)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DmwsrWCMwqn-"
      },
      "source": [
        "# 하이퍼파라미터를 변수로 둔다.\r\n",
        "\r\n",
        "# hyperparameters\r\n",
        "training_epochs = 15\r\n",
        "batch_size = 100"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BXtsUyOXwwt_"
      },
      "source": [
        "### 4.5.4 MNIST 분류기 구현하기\r\n",
        "\r\n",
        "torch.vision.datsets.dsets.MNIST 를 사용하여 MNIST 데이터셋을 불러올 수 있다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "46Wlb3W9w33i"
      },
      "source": [
        "# MNIST dataset\r\n",
        "mnist_train = dsets.MNIST(root='MNIST_data/',\r\n",
        "                          train=True,\r\n",
        "                          transform=transforms.ToTensor(),\r\n",
        "                          download=True)\r\n",
        "\r\n",
        "mnist_test = dsets.MNIST(root='MNIST_data/',\r\n",
        "                         train=False,\r\n",
        "                         transform=transforms.ToTensor(),\r\n",
        "                         download=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E7pSS5Cdw7Yr"
      },
      "source": [
        "첫 번째 인자 root 는 MNIST 데이터를 다운로드 받을 경로이다. \r\n",
        "\r\n",
        "두번째 인자 train은 인자로 True를 주면, MNIST의 훈련 데이터를 리턴받고 False를 주면 테스트 데이터를 리턴받는다.\r\n",
        "\r\n",
        " 세번째 인자 trasnform 은 현재 데이터를 파이토치텐서로 변환해준다. \r\n",
        " \r\n",
        " 네번째 인자 download 는 해당경로에 MNIST \r\n",
        "데이터가 없다면 다운로드 받겠다는 의미이다.\r\n",
        "\r\n",
        "이렇게 데이터를 다운로드했으면, 앞서 미니배치와 데이터 로드 챕터에서 학습했던 데이터로더를 사용한다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cPFQEtcKxVEE"
      },
      "source": [
        "#dataset loader\r\n",
        "\r\n",
        "data_loader = DataLoader(dataset = mnist_train,\r\n",
        "                         batch_size = batch_size, # 배치 크기는 100\r\n",
        "                         shuffle = True,\r\n",
        "                         drop_last = True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7lBTByubxfZI"
      },
      "source": [
        "이 때 DataLoader에는 4개의 인자가 있다.\r\n",
        "\r\n",
        "1. dataset : 로드할 대상을 의미\r\n",
        "2. batch_size : 배치 크기\r\n",
        "3. shuffle : 매 에포크마다 미니 배치를 셔플할 것인지\r\n",
        "4. drop_last : 마지막 배치를 버릴 것인지\r\n",
        "\r\n",
        "drop_last를 하는 이유를 이해하기 위해 1000개의 데이터가 있다고 했을 때, 배치 크기가 128이라고 해보자, 1,000 을 128로 나누면 7개가 나오고 104개가 남는다. 이때 104개를 마지막 배치로 한다고 했을 때 128개를 충족하지 못했으므로 그냥 104개를 버릴 수도 있다. 이때 마지막 배치를 버리려면 True로 설정해주면 된다. 이는 다른 미니 배치보다 개수가 적은 마지막 배치를 경사 하강법에 사용하여 마지막 배치가 상대적으로 과대평가되는 현상을 막아준다\r\n",
        "\r\n",
        "이제 모델을 설계한다. input_dim 은 784 이고, output_dim 은 10이다.\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8yJ1JcIZx80q"
      },
      "source": [
        "# MNIST data image of shape 28*28 = 784\r\n",
        "\r\n",
        "linear = nn.Linear(784, 10, bias =True).to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6fjnk72zyDC7"
      },
      "source": [
        "to() 함수는 연산을 어디서 수행할지를 정한다. to() 함수는 모델의 매개변수를 지정한 장치의 메모리로 보낸다. CPU를 사용하는 경우에는 필요가 없지만 GPU를 사용하려면 to('cuda')를 해줄 필요가 있다. 아무것도 지정하지 않는 경우에는 CPU 연산이라고 보면 된다.\r\n",
        "\r\n",
        "bias 는 편향 b 를 사용할 것인지를 나타낸다. 기본값은 True 이다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OTfriwahyUiX"
      },
      "source": [
        "# 비용 함수와 optimizer 정의\r\n",
        "\r\n",
        "criterion = nn.CrossEntropyLoss().to(device) # 내부적으로 소프트맥스 함수 포함\r\n",
        "optimizer = torch.optim.SGD(linear.parameters(), lr = 0.1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0eKsDOgNyhKc"
      },
      "source": [
        "앞서 소프트맥스 회귀를 배울 때는 torch.nn.functional.cross_entropy() 를 사용했으나, 여기서는 torch.nn.Cross.EntropyLoss()를 사용하고 있다. 둘 다 파이토치에서 제공하는 크로스 엔트로피 함수로 둘 다 소프트맥스 함수를 포함하고 있다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j5Yp4Ad4yr0k",
        "outputId": "5def8022-ee64-4cb7-c4f1-0ffb99853e41"
      },
      "source": [
        "for epoch in range(training_epochs): # 앞서 training_epochs 의 값은 15로 지정했었다.\r\n",
        "    avg_cost = 0\r\n",
        "    total_batch = len(data_loader)\r\n",
        "\r\n",
        "    for X,Y in data_loader:\r\n",
        "      # 배치 크기가 100이므로 아래의 연산에서 X 는 (100,784)의 텐서가 된다.\r\n",
        "      X = X.view(-1, 28*28).to(device)\r\n",
        "      # 레이블은 원-핫 인코딩이 된 상태가 아니라 0~9 사이의 정수\r\n",
        "      Y = Y.to(device)\r\n",
        "\r\n",
        "      optimizer.zero_grad()\r\n",
        "      hypothesis = linear(X)\r\n",
        "      cost = criterion(hypothesis,Y)\r\n",
        "      cost.backward()\r\n",
        "      optimizer.step()\r\n",
        "\r\n",
        "      avg_cost +=cost / total_batch\r\n",
        "\r\n",
        "    print('Epoch:', '%04d' % (epoch + 1), 'cost =', '{:.9f}'.format(avg_cost))\r\n",
        "\r\n",
        "print('Learning finished')\r\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 0001 cost = 0.288894027\n",
            "Epoch: 0002 cost = 0.285807252\n",
            "Epoch: 0003 cost = 0.282866865\n",
            "Epoch: 0004 cost = 0.280836403\n",
            "Epoch: 0005 cost = 0.278653204\n",
            "Epoch: 0006 cost = 0.276752770\n",
            "Epoch: 0007 cost = 0.275104433\n",
            "Epoch: 0008 cost = 0.273745686\n",
            "Epoch: 0009 cost = 0.272228450\n",
            "Epoch: 0010 cost = 0.271123946\n",
            "Epoch: 0011 cost = 0.269739419\n",
            "Epoch: 0012 cost = 0.268750042\n",
            "Epoch: 0013 cost = 0.267728657\n",
            "Epoch: 0014 cost = 0.266432613\n",
            "Epoch: 0015 cost = 0.265821218\n",
            "Learning finished\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 411
        },
        "id": "BIoQYLtJzREQ",
        "outputId": "9809ce87-012c-4f67-ece6-3d088a3e00f4"
      },
      "source": [
        "# 테스트 데이터를 사용하여 모델을 테스트한다.\r\n",
        "\r\n",
        "with torch.no_grad(): # torch.no_grad() 를 하면 gradient 계산을 하지 않는다.\r\n",
        "  X_test = mnist_test.test_data.view(-1, 28*28).float().to(device)\r\n",
        "  Y_test = mnist_test.test_labels.to(device)\r\n",
        "\r\n",
        "  prediction = linear(X_test)\r\n",
        "  correct_prediction = torch.argmax(prediction, 1) == Y_test\r\n",
        "  accuracy = correct_prediction.float().mean()\r\n",
        "  print('Accuracy:', accuracy.item())\r\n",
        "\r\n",
        "  # MNIST 테스트 데이터에서 무작위로 하나를 뽑아서 예측을 해본다\r\n",
        "\r\n",
        "  r = random.randint(0, len(mnist_test)-1)\r\n",
        "  X_single_data= mnist_test.test_data[r:r+1].view(-1,28*28).float().to(device)\r\n",
        "  Y_single_data = mnist_test.test_labels[r:r+1].to(device)\r\n",
        "\r\n",
        "  print('Label: ', Y_single_data.item())\r\n",
        "  single_prediction = linear(X_single_data)\r\n",
        "  print('Prediction: ', torch.argmax(single_prediction, 1).item())\r\n",
        "\r\n",
        "  plt.imshow(mnist_test.test_data[r:r+1].view(28,28), cmap='Greys', interpolation = 'nearest')\r\n",
        "  plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 0.8833000063896179\n",
            "Label:  8\n",
            "Prediction:  3\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torchvision/datasets/mnist.py:63: UserWarning: test_data has been renamed data\n",
            "  warnings.warn(\"test_data has been renamed data\")\n",
            "/usr/local/lib/python3.6/dist-packages/torchvision/datasets/mnist.py:53: UserWarning: test_labels has been renamed targets\n",
            "  warnings.warn(\"test_labels has been renamed targets\")\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Oa5kg0Cv0kj8"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EG4iooKwzPpp"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}